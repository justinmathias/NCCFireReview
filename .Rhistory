defaultW <- getOption("warn")
options(warn = -1)
sep <- dat |> separate({{in_col}}, into = c("Lat", "Lon"), sep = "\\/|\\,", convert = TRUE)
options(warn = defaultW)
return(sep$Lon)
} else {
return("Must be LatLon, Lat, or Lon")
}
}
x <- data.frame("latlon" =
c("43.5/-67.9",
"43.5,-67.9",
"43.5, -67.9",
"43.5 /-67.9"))
dat <- sep.coords(x, in_col = "latlon")
dat #It works!
# Dealing with units ------------------------------------------------------
#We will rely on the 'measurements' package to do the heavy lifting
convertSoilC <- function(val, from, to) {
#We want all units to be in terms of carbon
if (grepl("C", from) == TRUE) { #If the units are already in terms of carbon, then do simple conversion
from1 <- stri_replace_all_regex(from,
pattern=c('C', '_per_'), #Values to remove
replacement=c('', ' / '), #Values to replace with
vectorize=FALSE)
to1 <- stri_replace_all_regex(to,
pattern=c('_per_'), #Values to remove
replacement=c(' / '), #Values to replace with
vectorize=FALSE)
out <- conv_multiunit(val, from1, to1) #Use function from measurements package for conversion
out
} else {
val1 <- val #NEED TO PUT MODIFIER HERE
from1 <- stri_replace_all_regex(from, #Otherwise
pattern=c('C', '_per_'), #Values to remove
replacement=c('', ' / '), #Values to replace with
vectorize=FALSE)
to1 <- stri_replace_all_regex(to,
pattern=c('_per_'), #Values to remove
replacement=c(' / '), #Values to replace with
vectorize=FALSE)
out <- conv_multiunit(val1, from1, to1) #Use function from measurements package for conversion
out
}
}
#Create unique columns for Latitude and Longitude
bmap <- belowground |>
drop_na(LatLon) |> #Remove NA values only for LatLon column
select(LatLon) |>
group_by(LatLon) |> #Group by unique LatLon and only include one record per site
filter(row_number() == 1) |>
sep.coords(LatLon)
str(bmap)
View(bmap)
# Literature review datasheet metadata extraction -------------------------
#Read files, starting with row three, where actual
belowground <- read.xlsx("/Users/justinmathias/Downloads/Literature_Data_extraction_NCC_v2.xlsx",
sheet = "Belowground",
startRow = 3)
colnames(belowground)
#Create unique columns for Latitude and Longitude
bmap <- belowground |>
drop_na(LatLon) |> #Remove NA values only for LatLon column
select(LatLon) |>
group_by(LatLon) |> #Group by unique LatLon and only include one record per site
filter(row_number() == 1) |>
sep.coords(LatLon)
str(bmap)
##Belowground map of study locations----
biomes <- readOGR("/Users/justinmathias/Dropbox/Research/UIdaho Postdoc/Nature Climate Change review/Ecoregions2017/Ecoregions2017.shp") #World biomes from: Dinerstein et al., 2017, An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm
#Create a new dataframe, coords, so we can extract data from the CRU dataset for each year
coords <- data.frame(bmap$Lon, bmap$Lat)
coords.sp <- SpatialPoints(coords) #Coords need to be LongLat
proj4string(coords.sp) = proj4string(biomes) #Need to make sure coordinates match.
#Extract biome information.
bmap <- cbind(bmap, over(coords.sp, biomes)$BIOME_NAME)
#Rename biome column
names(bmap)[names(bmap) == "over(coords.sp, biomes)$BIOME_NAME"] <- "Biome"
####Map of bmap papers----
ggplot() + #Plot
borders("world", colour = "gray40", fill = "gray99") +
theme_article() +
coord_fixed(1.2) +
geom_point(aes(x = Lon, y = Lat, color = Biome),
data = bmap,
alpha = 0.65,
size = 2) +
scale_size_continuous(range = c(1, 8),
breaks = c(5, 10, 15)) +
theme(legend.position = "bottom",
legend.title = element_text(size = 11, family = "Arial"),
legend.text = element_text(size = 11, family = "Arial"),
legend.background=element_blank(),
axis.title.x = element_text(color = "black", size = 17, family = "Arial"),
axis.title.y = element_text(color = "black", size = 17, family = "Arial"),
axis.text = element_text(color = "black", size = 16, family = "Arial"),
panel.border = element_rect(colour = "black", fill=NA, size=.9),
plot.tag = element_text(family = "Arial", size = 18, face = "bold")) +
xlab("Longitude") +
ylab("Latitude") +
guides(color = guide_legend(override.aes = list(size=3, alpha = 0.8), ncol = 2))
# Summary stats -----------------------------------------------------------
bstats <- belowground |> select(12:29)
str(bstats)
bstats$LitterC <- as.numeric(bstats$LitterC)
str(bstats)
LitterC
bstats$LitterC
bstats$O_lyr <- as.numeric(bstats$O_lyr)
bstats$O_lyr
cols <- colnames(bstats)
# Summary stats -----------------------------------------------------------
bstats <- belowground |> select(12:29)
str(bstats)
cols <- colnames(bstats)
for (i in cols) {
bstats$paste0(i) <- as.numeric(bstats$paste0(i))
}
for (i in cols) {
bstats$paste0([i]) <- as.numeric(bstats$paste0([i]))
for (i in cols) {
bstats${paste0(i)} <- as.numeric(bstats${paste0(i)})
}
for (i in cols) {
bstats${{paste0(i)}} <- as.numeric(bstats${{paste0(i)}})
str(bstats)
bstats[] <- sapply(bstats, as.numeric)
str(bstats)
#Create unique columns for Latitude and Longitude
bmap <- belowground |>
drop_na(LatLon) |> #Remove NA values only for LatLon column
select(LatLon, 12:29) |>
group_by(LatLon) |> #Group by unique LatLon and only include one record per site
filter(row_number() == 1) |>
sep.coords(LatLon)
View(bmap)
str(bmap)
bmap[] <- sapply(bmap, as.numeric) #Assign all columns as numeric
####Map of bmap papers----
ggplot() + #Plot
borders("world", colour = "gray40", fill = "gray99") +
theme_article() +
coord_fixed(1.2) +
geom_point(aes(x = Lon, y = Lat, color = Biome),
data = bmap,
alpha = 0.65,
size = 2) +
scale_size_continuous(range = c(1, 8),
breaks = c(5, 10, 15)) +
theme(legend.position = "bottom",
legend.title = element_text(size = 11, family = "Arial"),
legend.text = element_text(size = 11, family = "Arial"),
legend.background=element_blank(),
axis.title.x = element_text(color = "black", size = 17, family = "Arial"),
axis.title.y = element_text(color = "black", size = 17, family = "Arial"),
axis.text = element_text(color = "black", size = 16, family = "Arial"),
panel.border = element_rect(colour = "black", fill=NA, size=.9),
plot.tag = element_text(family = "Arial", size = 18, face = "bold")) +
xlab("Longitude") +
ylab("Latitude") +
guides(color = guide_legend(override.aes = list(size=3, alpha = 0.8), ncol = 2))
##Belowground map of study locations----
biomes <- readOGR("/Users/justinmathias/Dropbox/Research/UIdaho Postdoc/Nature Climate Change review/Ecoregions2017/Ecoregions2017.shp") #World biomes from: Dinerstein et al., 2017, An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm
#Create a new dataframe, coords, so we can extract data from the CRU dataset for each year
coords <- data.frame(bmap$Lon, bmap$Lat)
coords.sp <- SpatialPoints(coords) #Coords need to be LongLat
proj4string(coords.sp) = proj4string(biomes) #Need to make sure coordinates match.
#Extract biome information.
bmap <- cbind(bmap, over(coords.sp, biomes)$BIOME_NAME)
#Rename biome column
names(bmap)[names(bmap) == "over(coords.sp, biomes)$BIOME_NAME"] <- "Biome"
####Map of bmap papers----
ggplot() + #Plot
borders("world", colour = "gray40", fill = "gray99") +
theme_article() +
coord_fixed(1.2) +
geom_point(aes(x = Lon, y = Lat, color = Biome),
data = bmap,
alpha = 0.65,
size = 2) +
scale_size_continuous(range = c(1, 8),
breaks = c(5, 10, 15)) +
theme(legend.position = "bottom",
legend.title = element_text(size = 11, family = "Arial"),
legend.text = element_text(size = 11, family = "Arial"),
legend.background=element_blank(),
axis.title.x = element_text(color = "black", size = 17, family = "Arial"),
axis.title.y = element_text(color = "black", size = 17, family = "Arial"),
axis.text = element_text(color = "black", size = 16, family = "Arial"),
panel.border = element_rect(colour = "black", fill=NA, size=.9),
plot.tag = element_text(family = "Arial", size = 18, face = "bold")) +
xlab("Longitude") +
ylab("Latitude") +
guides(color = guide_legend(override.aes = list(size=3, alpha = 0.8), ncol = 2))
####Map of bmap papers----
bmap |>
ggplot() + #Plot
borders("world", colour = "gray40", fill = "gray99") +
theme_article() +
coord_fixed(1.2) +
geom_point(aes(x = Lon, y = Lat, color = Biome),
alpha = 0.65,
size = 2) +
scale_size_continuous(range = c(1, 8),
breaks = c(5, 10, 15)) +
theme(legend.position = "bottom",
legend.title = element_text(size = 11, family = "Arial"),
legend.text = element_text(size = 11, family = "Arial"),
legend.background=element_blank(),
axis.title.x = element_text(color = "black", size = 17, family = "Arial"),
axis.title.y = element_text(color = "black", size = 17, family = "Arial"),
axis.text = element_text(color = "black", size = 16, family = "Arial"),
panel.border = element_rect(colour = "black", fill=NA, size=.9),
plot.tag = element_text(family = "Arial", size = 18, face = "bold")) +
xlab("Longitude") +
ylab("Latitude") +
guides(color = guide_legend(override.aes = list(size=3, alpha = 0.8), ncol = 2))
str(bstats) #Confirm numeric
bstats |> rowSums(na.rm = T)
bstats |> print()
bstats |> summarise_all(sum)
na.sum <- function() {
sum(..., na.rm = TRUE)
}
bstats |> summarise_all(na.sum)
na.sum <- function(...) {
sum(..., na.rm = TRUE)
}
bstats |> summarise_all(na.sum)
na.sum <- function(...) {
sum(..., na.rm = TRUE)
}
bstats |> summarise_all(na.sum)
bstats |> summarise_all(is.na())
bstats |> is.na()
bstats |> which(is.na())
bstats |> is.na()
library(isocalcR)
citation("isocalcR")
##Created on 9/26/2022 by Justin Mathias ##
##This script will serve as a central hub for commonly utilized functions for ##
##the NCC Fire Review.
#First, load all packages
library("easypackages")
libraries(c("tidyverse", "openxlsx", "measurements", "stringi"))
# Functions added by justin ----------------------------------------------------------
##Working with lat/lon----
#Let's start by creating functions that we will then wrap into a single function
#We will build out complexity later to deal with formatting
dms.to.dd <- function(dms, dms2 = NULL) {
if (is.null(dms2) != TRUE) {
dd <- round(as.numeric(conv_unit(dms, from = "deg_min_sec", to = "dec_deg")), 4)
dd2 <- round(as.numeric(conv_unit(dms2, from = "deg_min_sec", to = "dec_deg")), 4)
paste(dd, dd2, sep = ",")
} else if (is.null(dms2) == TRUE) {
dd <- round(as.numeric(conv_unit(dms, from = "deg_min_sec", to = "dec_deg")), 4)
dd
}
}
dd.to.dms <- function(dd, dd2) {
dms <- conv_unit(dd, from = "dec_deg", to = "deg_min_sec")
return(dms)
}
coord.convert <- function(coord, fn){
fns <- c("dms.to.dd", "dd.to.dms") #First list all possible functions
if(!fn %in% fns){
stop(paste0("Specified function must be one of:"), paste(fns, " ")) #Write error message if fn isn't listed
}
if(fn == "dms.to.dd"){ #Function for dms to dd
dd <- dms.to.dd(coord)
return(round(as.numeric(dd), 6))
} else if (fn == "dd.to.dms") { #Function for dd to dms
dms <- dd.to.dms(coord)
return(dms)
}
}
#Tests
coord.convert("21 35 45", "dms.to.dd") #It works!
#Parsing out data (works for parentheses and plus/minus)----
sep.data <- function(dat, in_col, return = "Both") {
if (return == "Both"){
defaultW <- getOption("warn")
options(warn = -1)
dat |> separate({{in_col}}, into = c("Value", "StdErr"), convert = TRUE)
} else if (return == "Value") {
defaultW <- getOption("warn")
options(warn = -1)
sep <- dat |> separate({{in_col}}, into = c("Value", "StdErr"), convert = TRUE)
options(warn = defaultW)
return(sep$Value)
} else if (return == "StdErr") {
defaultW <- getOption("warn")
options(warn = -1)
sep <- dat |> separate({{in_col}}, into = c("Value", "StdErr"), convert = TRUE)
options(warn = defaultW)
return(sep$StdErr)
} else {
return("Must be Both, Value, or StdErr")
}
}
x <- data.frame(Value = #Create test data frame
c("5(78)",
"4 (56)",
"4 ± 56",
"4±56"))
sep.data(x, in_col = Value) #Test! Works on parentheses and plus/minus!
#Parsing out lat/lon----
sep.coords <- function(dat, in_col, return = "LatLon") {
if (return == "LatLon"){
defaultW <- getOption("warn")
options(warn = -1)
dat |> separate({{in_col}}, into = c("Lat", "Lon"), sep = "\\/|\\,", convert = TRUE) #Separate can only handle one argument. Use regex to do the job
} else if (return == "Lat") {
defaultW <- getOption("warn")
options(warn = -1)
sep <- dat |> separate({{in_col}}, into = c("Lat", "Lon"), sep = "\\/|\\,", convert = TRUE)
options(warn = defaultW)
return(sep$Lat)
} else if (return == "Lon") {
defaultW <- getOption("warn")
options(warn = -1)
sep <- dat |> separate({{in_col}}, into = c("Lat", "Lon"), sep = "\\/|\\,", convert = TRUE)
options(warn = defaultW)
return(sep$Lon)
} else {
return("Must be LatLon, Lat, or Lon")
}
}
x <- data.frame("latlon" =
c("43.5/-67.9",
"43.5,-67.9",
"43.5, -67.9",
"43.5 /-67.9"))
dat <- sep.coords(x, in_col = "latlon")
dat #It works!
# Dealing with units ------------------------------------------------------
#We will rely on the 'measurements' package to do the heavy lifting
convertSoilC <- function(val, from, to) {
#We want all units to be in terms of carbon
if (grepl("C", from) == TRUE) { #If the units are already in terms of carbon, then do simple conversion
from1 <- stri_replace_all_regex(from,
pattern=c('C', '_per_'), #Values to remove
replacement=c('', ' / '), #Values to replace with
vectorize=FALSE)
to1 <- stri_replace_all_regex(to,
pattern=c('_per_'), #Values to remove
replacement=c(' / '), #Values to replace with
vectorize=FALSE)
out <- conv_multiunit(val, from1, to1) #Use function from measurements package for conversion
out
} else {
val1 <- val #NEED TO PUT MODIFIER HERE
from1 <- stri_replace_all_regex(from, #Otherwise
pattern=c('C', '_per_'), #Values to remove
replacement=c('', ' / '), #Values to replace with
vectorize=FALSE)
to1 <- stri_replace_all_regex(to,
pattern=c('_per_'), #Values to remove
replacement=c(' / '), #Values to replace with
vectorize=FALSE)
out <- conv_multiunit(val1, from1, to1) #Use function from measurements package for conversion
out
}
}
convertSoilC(1, "kgC_per_m2", "g / m2")
#Nature Climate Change review
#Created by Justin Mathias 9/26/2022
#Housekeeping: load packages, set themes, etc.
library("easypackages")
libraries(c("terra", "tidyverse", "ggsci", "ggthemes", "RColorBrewer", "measurements", "stringr", "rayshader", "egg", "rgdal", "openxlsx", "shiny", "shinydashboard",
"plotly"))
theme_set(theme_clean(base_size = 13)) #Set ggplot2 theme
# Carbon density ----------------------------------------------------------
#First, extract data for each biome using Dinerstein et al., 2017, An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm
biomes <- vect("/Users/justinmathias/Dropbox/Research/UIdaho Postdoc/NCCFireReview/Data/Ecoregions2017/Ecoregions2017.shp")
# Literature review datasheet metadata extraction -------------------------
#Read files, starting with row three, where actual column headers are
belowground <- read.xlsx("/Users/justinmathias/Downloads/Literature_Data_extraction_NCC_v2.xlsx",
sheet = "Belowground",
startRow = 3)
colnames(belowground)
#Create unique columns for Latitude and Longitude
bmap <- belowground |>
drop_na(LatLon) |> #Remove NA values only for LatLon column
select(LatLon, 12:29) |>
group_by(LatLon) |> #Group by unique LatLon and only include one record per site
filter(row_number() == 1) |>
sep.coords(LatLon)
bmap[] <- sapply(bmap, as.numeric) #Assign all columns as numeric
str(bmap)
##Belowground map of study locations----
biomes <- readOGR("/Users/justinmathias/Dropbox/Research/UIdaho Postdoc/Nature Climate Change review/Ecoregions2017/Ecoregions2017.shp") #World biomes from: Dinerstein et al., 2017, An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm
#Create a new dataframe, coords, so we can extract data from the CRU dataset for each year
coords <- data.frame(bmap$Lon, bmap$Lat)
coords.sp <- SpatialPoints(coords) #Coords need to be LongLat
proj4string(coords.sp) = proj4string(biomes) #Need to make sure coordinates match.
#Extract biome information.
bmap <- cbind(bmap, over(coords.sp, biomes)$BIOME_NAME)
#Rename biome column
names(bmap)[names(bmap) == "over(coords.sp, biomes)$BIOME_NAME"] <- "Biome"
str(bmap)
####Map of bmap papers----
bmap |>
ggplot() + #Plot
borders("world", colour = "gray40", fill = "gray99") +
theme_article() +
coord_fixed(1.2) +
geom_point(aes(x = Lon, y = Lat, color = Biome),
alpha = 0.65,
size = 2) +
scale_size_continuous(range = c(1, 8),
breaks = c(5, 10, 15)) +
theme(
legend.position = "bottom",
legend.title = element_text(size = 11, family = "Arial"),
legend.text = element_text(size = 11, family = "Arial"),
legend.background = element_blank(),
axis.title.x = element_text(
color = "black",
size = 17,
family = "Arial"
),
axis.title.y = element_text(
color = "black",
size = 17,
family = "Arial"
),
axis.text = element_text(
color = "black",
size = 16,
family = "Arial"
),
panel.border = element_rect(
colour = "black",
fill = NA,
size = .9
),
plot.tag = element_text(
family = "Arial",
size = 18,
face = "bold"
)
) +
xlab("Longitude") +
ylab("Latitude") +
guides(color = guide_legend(override.aes = list(size = 3, alpha = 0.8), ncol = 2))
# Literature review datasheet metadata extraction -------------------------
#Read files, starting with row three, where actual column headers are
belowground <- read.xlsx("/Users/justinmathias/Downloads/Literature_Data_extraction_NCC_v2.xlsx",
sheet = "Belowground",
startRow = 3)
colnames(belowground)
#Create unique columns for Latitude and Longitude
bmap <- belowground |>
drop_na(LatLon) |> #Remove NA values only for LatLon column
select(LatLon, 12:29) |>
group_by(LatLon) |> #Group by unique LatLon and only include one record per site
filter(row_number() == 1) |>
sep.coords(LatLon)
bmap[] <- sapply(bmap, as.numeric) #Assign all columns as numeric
str(bmap)
##Belowground map of study locations----
biomes <- readOGR("/Users/justinmathias/Dropbox/Research/UIdaho Postdoc/Nature Climate Change review/Ecoregions2017/Ecoregions2017.shp") #World biomes from: Dinerstein et al., 2017, An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm
#Create a new dataframe, coords, so we can extract data from the CRU dataset for each year
coords <- data.frame(bmap$Lon, bmap$Lat)
coords.sp <- SpatialPoints(coords) #Coords need to be LongLat
proj4string(coords.sp) = proj4string(biomes) #Need to make sure coordinates match.
#Extract biome information.
bmap <- cbind(bmap, over(coords.sp, biomes)$BIOME_NAME)
#Rename biome column
names(bmap)[names(bmap) == "over(coords.sp, biomes)$BIOME_NAME"] <- "Biome"
str(bmap)
# Literature review datasheet metadata extraction -------------------------
#Read files, starting with row three, where actual column headers are
belowground <- read.xlsx("/Users/justinmathias/Downloads/Literature_Data_extraction_NCC_v2.xlsx",
sheet = "Belowground",
startRow = 3)
colnames(belowground)
#Create unique columns for Latitude and Longitude
bmap <- belowground |>
drop_na(LatLon) |> #Remove NA values only for LatLon column
select(LatLon, 12:29) |>
group_by(LatLon) |> #Group by unique LatLon and only include one record per site
filter(row_number() == 1) |>
sep.coords(LatLon)
bmap[] <- sapply(bmap, as.numeric) #Assign all columns as numeric
str(bmap)
#Create a new dataframe, coords, so we can extract data from the CRU dataset for each year
coords <- data.frame(bmap$Lon, bmap$Lat)
coords.sp <- SpatialPoints(coords) #Coords need to be LongLat
proj4string(coords.sp) = proj4string(biomes) #Need to make sure coordinates match.
#Extract biome information.
bmap <- cbind(bmap, over(coords.sp, biomes)$BIOME_NAME)
#Rename biome column
names(bmap)[names(bmap) == "over(coords.sp, biomes)$BIOME_NAME"] <- "Biome"
str(bmap)
View(bmap)
# Literature review datasheet metadata extraction -------------------------
#Read files, starting with row three, where actual column headers are
belowground <- read.xlsx("/Users/justinmathias/Downloads/Literature_Data_extraction_NCC_v2.xlsx",
sheet = "Belowground",
startRow = 3)
colnames(belowground)
#Create unique columns for Latitude and Longitude
bmap <- belowground |>
drop_na(LatLon) |> #Remove NA values only for LatLon column
select(LatLon, 12:29) |>
group_by(LatLon) |> #Group by unique LatLon and only include one record per site
filter(row_number() == 1) |>
sep.coords(LatLon)
bmap[] <- sapply(bmap, as.numeric) #Assign all columns as numeric
str(bmap)
